{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "retraining-stylegan2-tf.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmFeV_9q0XS-"
      },
      "source": [
        "# Retraining StyleGAN2 on Kaggle\n",
        "\n",
        "Inspired by Jeff Heaton's Google Colab and Docker examples on training StyleGAN2\n",
        "\n",
        "https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_style_gan.ipynb\n",
        "https://hub.docker.com/r/heatonresearch/stylegan2-ada\n",
        "\n",
        "\n",
        "## Background\n",
        "\n",
        "StyleGAN2 requires a Windows or Linux machine with at least 1 GPU. My computer meets neither requirement so I ran a notebook using Kaggle's GPU time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dRAFoDW0lR2"
      },
      "source": [
        "# Load Google Drive Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxbggP9O0klq",
        "outputId": "798a1d80-8409-471d-85d0-d9e46fe73ebe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt3DKELf0XTD"
      },
      "source": [
        "# Clone the StyleGAN ADA Repository and Install Packages\n",
        "\n",
        "Run the code block below to clone the repository and switch tensorflow versions. I found that if you try to manually pip install tensorflow, you will run into missing GPU issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-30T15:25:29.50778Z",
          "iopub.execute_input": "2021-11-30T15:25:29.508491Z",
          "iopub.status.idle": "2021-11-30T15:26:23.304554Z",
          "shell.execute_reply.started": "2021-11-30T15:25:29.508446Z",
          "shell.execute_reply": "2021-11-30T15:26:23.303299Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgQHrXyE0XTE",
        "outputId": "1f22655a-3211-410e-a495-fffcd7bdd243"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stylegan2' already exists and is not an empty directory.\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyhxI-KS0XTF"
      },
      "source": [
        "Check that the repository was downloaded. If you are not running in Kaggle, you should change the path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-30T15:26:23.306703Z",
          "iopub.execute_input": "2021-11-30T15:26:23.307119Z",
          "iopub.status.idle": "2021-11-30T15:26:24.073845Z",
          "shell.execute_reply.started": "2021-11-30T15:26:23.307051Z",
          "shell.execute_reply": "2021-11-30T15:26:24.072738Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RDCCiba0XTF",
        "outputId": "500c2a3a-0bb2-430d-ccf9-bde0680cf359"
      },
      "source": [
        "!ls /content/stylegan2/\n",
        "!ls /content/drive/MyDrive/StyleGAN2_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_tool.py  LICENSE.txt\t\t README.md\t   run_training.py\n",
            "dnnlib\t\t metrics\t\t run_generator.py  test_nvcc.cu\n",
            "Dockerfile\t pretrained_networks.py  run_metrics.py    training\n",
            "docs\t\t projector.py\t\t run_projector.py\n",
            "images\timages.zip  pytorch-dataset  tf-datasets  tf-results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2vRjGe30XTG"
      },
      "source": [
        "Verify Tensorflow version 1.x and GPU access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-30T15:26:24.078951Z",
          "iopub.execute_input": "2021-11-30T15:26:24.079226Z",
          "iopub.status.idle": "2021-11-30T15:26:26.673278Z",
          "shell.execute_reply.started": "2021-11-30T15:26:24.079178Z",
          "shell.execute_reply": "2021-11-30T15:26:26.670427Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnIFTprF0XTG",
        "outputId": "3238ee67-fb98-4575-ceb4-3b5a91b2956c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()  \n",
        "if device_name != '/device:GPU:0':\n",
        "   raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8wJrWuN0XTH"
      },
      "source": [
        "# Convert your images to data format\n",
        "\n",
        "If you have already run this section before, you do not need to run it again.\n",
        "\n",
        "You need to convert your images to a data format for StyleGAN2. Your images must be square and have dimensions with a power of 2 (ex 256 x 256).\n",
        "\n",
        "In the command below, you should specify the source path to all your input JPEG images (ie as a zip file) as well as the destination path to store the output dataset. Note that your dataset path should follow the format ```<path/to/your/datasets>/<your-dataset-name>```. Later when you run ```run_training.py```, you will need to pass ```path/to/your/datasets``` to ```data-dir``` and ```your-dataset-name``` to ```dataset```.\n",
        "\n",
        "If you are not in Colab, you should change the argument paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-30T15:26:26.675573Z",
          "iopub.execute_input": "2021-11-30T15:26:26.675938Z",
          "iopub.status.idle": "2021-11-30T15:35:45.932311Z",
          "shell.execute_reply.started": "2021-11-30T15:26:26.675888Z",
          "shell.execute_reply": "2021-11-30T15:35:45.930439Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ov6Bg10XTH",
        "outputId": "c2e130f8-8651-4313-b289-757cf140806b"
      },
      "source": [
        "#!python /content/stylegan2/dataset_tool.py create_from_images  /content/drive/MyDrive/StyleGAN2_data/tf-datasets/custom/ /content/drive/MyDrive/StyleGAN2_data/images/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Loading images from \"/content/drive/My Drive/StyleGAN2_data/images/\"\n",
            "Creating dataset \"/content/drive/My Drive/StyleGAN2_data/tf-datasets/custom/\"\n",
            "/content/stylegan2/dataset_tool.py:86: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 20701 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64A6s4z84u3-"
      },
      "source": [
        "Confirm you have tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBZXjjCBANHM",
        "outputId": "05e9bc09-5300-470e-835b-c0ef0b958852"
      },
      "source": [
        "!ls /content/drive/MyDrive/StyleGAN2_data/tf-datasets/custom"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-r02.tfrecords\t-r04.tfrecords\t-r06.tfrecords\t-r08.tfrecords\n",
            "-r03.tfrecords\t-r05.tfrecords\t-r07.tfrecords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB5JQ7_I0XTH"
      },
      "source": [
        "# Train StyleGAN2 on your images!\n",
        "\n",
        "If you want to resume training from a network snapshot, you need to upload that snapshot as a dataset to Kaggle, then connect the dataset to this notebook. You must also pass in the --resume flag and the model path.\n",
        "\n",
        "If you are not in Kaggle, you should change the argument paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-30T16:27:31.088942Z",
          "iopub.execute_input": "2021-11-30T16:27:31.089318Z",
          "iopub.status.idle": "2021-11-30T16:28:45.798892Z",
          "shell.execute_reply.started": "2021-11-30T16:27:31.089269Z",
          "shell.execute_reply": "2021-11-30T16:28:45.79718Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2a1eTlr0XTI",
        "outputId": "69f387ef-a9be-4811-8f4d-4003c4652c35"
      },
      "source": [
        "!python /content/stylegan2/run_training.py --num-gpus=1 --dataset=custom --data-dir=/content/drive/MyDrive/StyleGAN2_data/tf-datasets --config=config-f --mirror-augment=true --total-kimg=1000 --result-dir=/content/drive/MyDrive/StyleGAN2_data/tf-results --metrics=none"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local submit - run_dir: /content/drive/MyDrive/StyleGAN2_data/tf-results/00008-stylegan2-custom-1gpu-config-f\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x564ae953a000 @  0x7f361b5fa001 0x7f36180de54f 0x7f361812eb58 0x7f3618132b17 0x7f36181d1203 0x564ae324a544 0x564ae324a240 0x564ae32be627 0x564ae32b8ced 0x564ae324c48c 0x564ae328d159 0x564ae328a0a4 0x564ae324c698 0x564ae32bafe4 0x564ae32b89ee 0x564ae318ae2b 0x564ae32bafe4 0x564ae32b89ee 0x564ae318ae2b 0x564ae32bafe4 0x564ae324bafa 0x564ae32b9915 0x564ae324bafa 0x564ae32b9c0d 0x564ae32b89ee 0x564ae318ae2b 0x564ae32bafe4 0x564ae32b89ee 0x564ae318ae2b 0x564ae32bafe4 0x564ae324bafa\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x564be953a000 @  0x7f361b5f81e7 0x7f36180de46e 0x7f361812ec7b 0x7f361812f35f 0x7f36181d1103 0x564ae324a544 0x564ae324a240 0x564ae32be627 0x564ae32b89ee 0x564ae324bbda 0x564ae32ba737 0x564ae32b89ee 0x564ae324bbda 0x564ae32ba737 0x564ae32b89ee 0x564ae324bbda 0x564ae32ba737 0x564ae324bafa 0x564ae32b9915 0x564ae32b89ee 0x564ae324bbda 0x564ae32bdd00 0x564ae32b89ee 0x564ae324bbda 0x564ae32ba737 0x564ae32b8ced 0x564ae324c48c 0x564ae328d159 0x564ae328a0a4 0x564ae324c698 0x564ae32bafe4\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x564ce9d58000 @  0x7f361b5f81e7 0x7f36180de46e 0x7f361812ec7b 0x7f361812f35f 0x7f35d3e4b235 0x7f35d37ce792 0x7f35d37ced42 0x7f35d3787aee 0x564ae324a437 0x564ae324a240 0x564ae32be0f3 0x564ae324bafa 0x564ae32b9c0d 0x564ae32b8ced 0x564ae318aeb0 0x564ae32bafe4 0x564ae32b89ee 0x564ae324bbda 0x564ae32b9c0d 0x564ae32b8ced 0x564ae324bbda 0x564ae32b9c0d 0x564ae324bafa 0x564ae32b9c0d 0x564ae32b89ee 0x564ae324c271 0x564ae324c698 0x564ae32bafe4 0x564ae32b89ee 0x564ae324bbda 0x564ae32b9915\n",
            "Dataset shape = [3, 256, 256]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 14, 512)        -               \n",
            "Truncation/Lerp               -         (?, 14, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 14, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/images_out        -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "images_out                    -         (?, 3, 256, 256)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30034338                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 256, 256)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "256x256/FromRGB      512       (?, 128, 256, 256)  (1, 1, 3, 128)  \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "scores_out           -         (?, 1)              -               \n",
            "---                  ---       ---                 ---             \n",
            "Total                28864129                                      \n",
            "\n",
            "Building TensorFlow graph...\n",
            "Initializing logs...\n",
            "Training for 1000 kimg...\n",
            "\n",
            "tick 0     kimg 0.1      lod 0.00  minibatch 32   time 3m 39s       sec/tick 219.0   sec/kimg 1710.93 maintenance 0.0    gpumem 6.1\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}